{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1A9KwN6O27-pR4_n00FGt84CJ0fob35j-","authorship_tag":"ABX9TyO09JL0B9bP3adBGmyUq1Ly"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Resume Screener"],"metadata":{"id":"1WkrUspPTNZY"}},{"cell_type":"code","execution_count":21,"metadata":{"id":"j9SXmTj9745G","executionInfo":{"status":"ok","timestamp":1679164369390,"user_tz":-330,"elapsed":2,"user":{"displayName":"Kausthub Kannan","userId":"16531519236785994511"}}},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.activations import tanh\n","from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n","import tensorflow.keras.layers as layers\n","import re\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.multiclass import OneVsRestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","#Helper Function\n","def cleanResume(resumeText):\n","    resumeText = re.sub('httpS+s*', ' ', resumeText)  # remove URLs\n","    resumeText = re.sub('RT|cc', ' ', resumeText)  # remove RT and cc\n","    resumeText = re.sub('#S+', '', resumeText)  # remove hashtags\n","    resumeText = re.sub('@S+', '  ', resumeText)  # remove mentions\n","    resumeText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[]^_`{|}~\"\"\"), ' ', resumeText)  # remove punctuations\n","    resumeText = re.sub(r'[^x00-x7f]',r' ', resumeText) \n","    resumeText = re.sub('s+', ' ', resumeText)  # remove extra whitespace\n","    return resumeText"]},{"cell_type":"markdown","source":["## Data Load and Pre processing"],"metadata":{"id":"TorhPnlTTT1D"}},{"cell_type":"code","source":["#Loading Data\n","data_path='/content/drive/MyDrive/Colab Notebooks/Resume Recommendation/UpdatedResumeDataSet.csv'\n","df = pd.read_csv(data_path)\n","\n","#Pre preprocessing\n","#Regex\n","df['cleaned_resume'] = df.Resume.apply(lambda x: cleanResume(x))\n","\n","#Encoding labels\n","var_mod = ['Category']\n","classes = df['Category'].unique()\n","le = LabelEncoder()\n","for i in var_mod:\n","    df[i] = le.fit_transform(df[i])\n","\n","#Vectorization\n","requiredText = df['cleaned_resume'].values\n","requiredTarget = df['Category'].values\n","word_vectorizer = TfidfVectorizer(\n","    sublinear_tf=True,\n","    stop_words='english',\n","    max_features=1500)\n","word_vectorizer.fit(requiredText)\n","WordFeatures = word_vectorizer.transform(requiredText)\n","\n","#Splitting the data\n","X_train,X_test,y_train,y_test = train_test_split(WordFeatures,requiredTarget,random_state=0, test_size=0.2)"],"metadata":{"id":"9TL4l3_i8KfG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Model"],"metadata":{"id":"ZyVfGtDVUwPd"}},{"cell_type":"code","source":["#Train and Fit\n","clf = OneVsRestClassifier(KNeighborsClassifier())\n","clf.fit(X_train, y_train)\n","\n","#Accuracy Score\n","print('Accuracy of KNeighbors Classifier on training set: {:.2f}'.format(clf.score(X_train, y_train)))\n","print('Accuracy of KNeighbors Classifier on test set: {:.2f}'.format(clf.score(X_test, y_test)))\n","\n","#Prediction of class (Job)\n","prediction = clf.predict(X_test)\n","for preds in prediction:\n","  print(classes[preds])"],"metadata":{"id":"fILYqD5t_YJt","executionInfo":{"status":"ok","timestamp":1679164431522,"user_tz":-330,"elapsed":59139,"user":{"displayName":"Kausthub Kannan","userId":"16531519236785994511"}}},"execution_count":22,"outputs":[]}]}