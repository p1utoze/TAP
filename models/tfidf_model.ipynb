{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kneed, plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cluster import KMeans \n",
    "from kneed import KneeLocator\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import pickle \n",
    "warnings.filterwarnings('ignore')\n",
    "sys.path.append(\"..\")\n",
    "from modules import helper_functions as hf\n",
    "from modules import similarity_functions as sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = pd.read_csv(\"../data/df_job_final.csv\",  usecols=['title', 'department', 'description_combined'])\n",
    "df_resume = pd.read_csv(\"../data/data_resume_cc.csv\", usecols=['Category', 'Resume_c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 50\n",
    "print(f'length of job data before filtering: {len(df_jobs)}')\n",
    "df_jobs = hf.get_map_category(df_jobs, 'department', THRESHOLD )\n",
    "print(f'length of job data after filtering: {len(df_jobs)}')\n",
    "\n",
    "print(f'length of resume data before filtering: {len(df_resume)}')\n",
    "df_resume = hf.get_map_category(df_resume, 'Category', THRESHOLD)\n",
    "print(f'length of resume data after filtering: {len(df_resume)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = go.Figure()\n",
    "# resume_category = df_resume['Category'].value_counts()\n",
    "# keys = resume_category.keys()\n",
    "# list_y = [count for count in resume_category]\n",
    "\n",
    "# fig.add_trace(go.Bar(x = keys,\n",
    "#                     y = list_y,\n",
    "#                     text= list_y))\n",
    "# fig.update_layout(\n",
    "#     title_text='Resume Data'\n",
    "# )\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = go.Figure()\n",
    "# job_department = df_jobs['department'].value_counts()\n",
    "# keys = job_department.keys()\n",
    "# list_y = [count for count in job_department]\n",
    "\n",
    "# fig.add_trace(go.Bar(x = keys,\n",
    "#                     y = list_y,\n",
    "#                     text= list_y))\n",
    "# fig.update_layout(\n",
    "#     title_text='Job Data'\n",
    "# )\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data persistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to pickle\n",
    "tfidf_jobs = TfidfVectorizer()\n",
    "# Generate matrix of word vectors\n",
    "tfidf_job_matrix = tfidf_jobs.fit_transform(df_jobs['description_combined'])\n",
    "df_tfidf_jobs = pd.DataFrame(tfidf_job_matrix.toarray())\n",
    "df_tfidf_jobs.columns = tfidf_jobs.get_feature_names_out()\n",
    "path = './pretrained/tfidf_myjob.pkl'\n",
    "hf.save_tfidf(path, tfidf_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = hf.load_tfidf('./pretrained/tfidf_myjob.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from pickle\n",
    "# vec = hf.load_tfidf('./pretrained/tfidf_job.pkl')\n",
    "# svm_clf = hf.load_tfidf('./pretrained/tfidf_clf.pkl')\n",
    "# kmean_model = hf.load_tfidf('./pretrained/tfidf_cluster.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Validation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "enc = OrdinalEncoder()\n",
    "df_jobs['encoded_department'] = enc.fit_transform(df_jobs[['department']])\n",
    "\n",
    "df_jobs_nan = df_jobs[df_jobs['department'].isna() == True]\n",
    "df_jobs = df_jobs[df_jobs['department'].isna() == False]\n",
    "# train_test_val 60, 20, 20\n",
    "x_train_60, x_val_20, x_test_20, y_train_60, y_val_20, y_test_20 = hf.train_val_test_split(df_jobs['description_combined'], df_jobs['department'],0.6, 0.2, 0.2)\n",
    "# train_test_val 70, 15, 15\n",
    "x_train_70, x_val_15, x_test_15, y_train_70, y_val_15, y_test_15 = hf.train_val_test_split(df_jobs['description_combined'], df_jobs['department'],0.7, 0.15, 0.15)\n",
    "# train_test_val 80, 10, 10\n",
    "x_train_80, x_val_10, x_test_10, y_train_80, y_val_10, y_test_10 = hf.train_val_test_split(df_jobs['description_combined'], df_jobs['department'],0.8, 0.1, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tunning and choose best classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clfs = dict()\n",
    "crit= [{\"alpha\": [0.001, 0.01, 0.1, 1], \"fit_prior\": [True, False]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunned_nb_estimator = hf.tunning(model=MultinomialNB(),\n",
    "                                     vectorizer=vec,\n",
    "                                     crit=crit,\n",
    "                                     cv=10,\n",
    "                                     x=x_train_60,\n",
    "                                     y=y_train_60)\n",
    "\n",
    "nb_clfs['60'] = hf.get_classification_model_performance(tunned_nb_estimator, vec,\n",
    "                                                        x_train_60, x_test_20, x_val_20,\n",
    "                                                        y_train_60, y_test_20, y_val_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunned_nb_estimator = hf.tunning(model=MultinomialNB(),\n",
    "                                     vectorizer=vec,\n",
    "                                     crit=crit,\n",
    "                                     cv=10,\n",
    "                                     x=x_train_70,\n",
    "                                     y=y_train_70)\n",
    "\n",
    "nb_clfs['70'] = nb_clfs['60'] = hf.get_classification_model_performance(tunned_nb_estimator, vec,\n",
    "                                                        x_train_70, x_test_15, x_val_15,\n",
    "                                                        y_train_70, y_test_15, y_val_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunned_nb_estimator = hf.tunning(model=MultinomialNB(),\n",
    "                                     vectorizer=vec,\n",
    "                                     crit=crit,\n",
    "                                     cv=10,\n",
    "                                     x=x_train_80,\n",
    "                                     y=y_train_80)\n",
    "\n",
    "nb_clfs['80'] = hf.get_classification_model_performance(tunned_nb_estimator, vec,\n",
    "                                                        x_train_80, x_test_10, x_val_10,\n",
    "                                                        y_train_80, y_test_10, y_val_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clfs = dict()\n",
    "crit= [{\"C\": [0.01, 0.1, 1],\n",
    "        \"kernel\":['linear','poly','rbf']} # note that, all the segmoid kernel cases failed in the fitting process, so it's omitted\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunned_svm_estimator = hf.tunning(model= SVC(),\n",
    "                                     vectorizer=vec,\n",
    "                                     crit=crit,\n",
    "                                     cv=10,\n",
    "                                     x=x_train_60,\n",
    "                                     y=y_train_60)\n",
    "                                     \n",
    "svm_clfs['60'] = hf.get_classification_model_performance(tunned_svm_estimator, vec,\n",
    "                                                        x_train_60, x_test_20, x_val_20,\n",
    "                                                        y_train_60, y_test_20, y_val_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunned_svm_estimator = hf.tunning(model= SVC(),\n",
    "                                     vectorizer=vec,\n",
    "                                     crit=crit,\n",
    "                                     cv=10,\n",
    "                                     x=x_train_70,\n",
    "                                     y=y_train_70)\n",
    "\n",
    "svm_clfs['70'] = hf.get_classification_model_performance(tunned_svm_estimator, vec,\n",
    "                                                        x_train_70, x_test_15, x_val_15,\n",
    "                                                        y_train_70, y_test_15, y_val_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunned_svm_estimator = hf.tunning(model= SVC(),\n",
    "                                     vectorizer=vec,\n",
    "                                     crit=crit,\n",
    "                                     cv=10,\n",
    "                                     x=x_train_60,\n",
    "                                     y=y_train_60)\n",
    "\n",
    "svm_clfs['80'] = hf.get_classification_model_performance(tunned_svm_estimator, vec,\n",
    "                                                        x_train_80, x_test_10, x_val_10,\n",
    "                                                        y_train_80, y_test_10, y_val_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clfs = dict()\n",
    "crit= [{\"n_neighbors\":range(4,15),\n",
    "        \"weights\": ['uniform', 'distance']}\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunned_knn_estimator = hf.tunning(model= KNeighborsClassifier(),\n",
    "                                     vectorizer=vec,\n",
    "                                     crit=crit,\n",
    "                                     cv=10,\n",
    "                                     x=x_train_60,\n",
    "                                     y=y_train_60)\n",
    "                                     \n",
    "knn_clfs['60'] = hf.get_classification_model_performance(tunned_knn_estimator, vec,\n",
    "                                                        x_train_60, x_test_20, x_val_20,\n",
    "                                                        y_train_60, y_test_20, y_val_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunned_knn_estimator = hf.tunning(model= KNeighborsClassifier(),\n",
    "                                     vectorizer=vec,\n",
    "                                     crit=crit,\n",
    "                                     cv=10,\n",
    "                                     x=x_train_70,\n",
    "                                     y=y_train_70)\n",
    "\n",
    "knn_clfs['70'] = hf.get_classification_model_performance(tunned_knn_estimator, vec,\n",
    "                                                        x_train_70, x_test_15, x_val_15,\n",
    "                                                        y_train_70, y_test_15, y_val_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunned_knn_estimator = hf.tunning(model= KNeighborsClassifier(),\n",
    "                                     vectorizer=vec,\n",
    "                                     crit=crit,\n",
    "                                     cv=10,\n",
    "                                     x=x_train_80,\n",
    "                                     y=y_train_80)\n",
    "\n",
    "knn_clfs['80'] = hf.get_classification_model_performance(tunned_knn_estimator, vec,\n",
    "                                                        x_train_80, x_test_10, x_val_10,\n",
    "                                                        y_train_80, y_test_10, y_val_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "SET_RED = np.arange(0, 255,30)\n",
    "SET_GREEN = [120] * len(SET_RED)\n",
    "SET_BLUE = np.arange(235, 10, -25)\n",
    "evaluation = ['accuracy', 'cv', 'macro_precision', 'macro_recall', 'macro_f1_score', 'time_cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ['nb_clf_60', 'nb_clf_70', 'nb_clf_80',\n",
    "            'svm_clf_60', 'svm_clf_70', 'svm_clf_80',\n",
    "            'knn_clf_60', 'knn_clf_70', 'knn_clf_80']\n",
    "            \n",
    "dict_evaluation = dict()\n",
    "dict_evaluation['estimator'] = []\n",
    "dict_evaluation['accuracy'] = []\n",
    "dict_evaluation['cv10'] = []\n",
    "dict_evaluation['precision'] = []\n",
    "dict_evaluation['recall'] = []\n",
    "dict_evaluation['f1_score'] = []\n",
    "dict_evaluation['time_cost'] = []\n",
    "\n",
    "for train_size in nb_clfs:\n",
    "    for key in nb_clfs[train_size]:\n",
    "        dict_evaluation[key].append(nb_clfs[train_size][key])\n",
    "\n",
    "for train_size in svm_clfs:\n",
    "    for key in nb_clfs[train_size]:\n",
    "        dict_evaluation[key].append(svm_clfs[train_size][key])\n",
    "\n",
    "for train_size in knn_clfs:\n",
    "    for key in nb_clfs[train_size]:\n",
    "        dict_evaluation[key].append(knn_clfs[train_size][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\"\n",
    "fig = go.Figure()\n",
    "keys = ['accuracy', 'precision', 'recall', 'f1_score', 'cv10']\n",
    "\n",
    "for i, color_feature in enumerate(SET_RED):\n",
    "    list_y = [dict_evaluation[key][i] for key in keys]\n",
    "    fig.add_trace(go.Bar(x = keys,\n",
    "                        y = list_y,\n",
    "                        name = model_name[i],\n",
    "                        marker_color= f'rgb({SET_RED[i]}, {SET_GREEN[i]}, {SET_BLUE[i]})',\n",
    "                        text= list_y\n",
    "                        ))\n",
    "\n",
    "fig.update_traces(texttemplate='%{text:.3f}', textposition='outside')\n",
    "fig.update_layout(\n",
    "    title_text='Different Models Accuracy-Precision-Recall-F1',\n",
    "    title_x=0.5,\n",
    "    xaxis_tickfont_size=16,\n",
    "    yaxis=dict(\n",
    "        title='Score',\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=16,\n",
    "    ),\n",
    "    legend=dict(\n",
    "    orientation=\"h\",\n",
    "    yanchor=\"top\",\n",
    "    y=-0.1,\n",
    "    xanchor=\"left\",\n",
    "    x=-0.04\n",
    "    ),\n",
    "\n",
    "    barmode='group',\n",
    "    bargap=0.15, # gap between bars of adjacent location coordinates.\n",
    "    bargroupgap=0.1 # gap between bars of the same location coordinate.\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "keys = ['time_cost']\n",
    "for i, color_feature in enumerate(SET_RED):\n",
    "    list_y = [dict_evaluation[key][i] for key in keys]\n",
    "    fig.add_trace(go.Bar(x = keys,\n",
    "                        y = list_y,\n",
    "                        name = model_name[i],\n",
    "                        marker_color= f'rgb({SET_RED[i]}, {SET_GREEN[i]}, {SET_BLUE[i]})',\n",
    "                        text= list_y\n",
    "                        ))\n",
    "\n",
    "fig.update_traces(texttemplate='%{text:.3f}', textposition='outside')\n",
    "fig.update_layout(\n",
    "    title_text='Time Cost for Training',\n",
    "    title_x=0.5,\n",
    "    xaxis_tickfont_size=16,\n",
    "    yaxis=dict(\n",
    "        title='minutes',\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=16,\n",
    "    ),\n",
    "    legend=dict(\n",
    "    orientation=\"h\",\n",
    "    yanchor=\"top\",\n",
    "    y=-0.1,\n",
    "    xanchor=\"left\",\n",
    "    x=-0.04\n",
    "    ),\n",
    "\n",
    "    barmode='group',\n",
    "    bargap=0.15, # gap between bars of adjacent location coordinates.\n",
    "    bargroupgap=0.1 # gap between bars of the same location coordinate.\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-based RS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Models(Naive Bayes, SVM, KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a classification model based on job description\n",
    "nb_clf = Pipeline([\n",
    "    ('tf', vec),\n",
    "    ('clf', nb_clfs['60']['estimator']),\n",
    "])\n",
    "\n",
    "nb_clf.fit(x_train_60, y_train_60)\n",
    "pred = nb_clf.predict(x_test_20)\n",
    "pred_resume = nb_clf.predict(df_resume['Resume_c'])\n",
    "accuracy = np.mean(pred_resume == df_resume['Category'])\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get confusion matrix\n",
    "unique_labels = np.unique(df_jobs['department'])\n",
    "cf_report = hf.get_classification_report(unique_labels, y_test_20, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select one user, recommend top-10 jobs\n",
    "applicant = df_resume.iloc[0]\n",
    "# model predict category of the resume\n",
    "pred_applicant = nb_clf.predict([applicant['Resume_c']])[0]\n",
    "pred_applicant == applicant['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_top_n = hf.get_top_n_jobs_from_clf(df_jobs, pred_applicant, applicant['Resume_c'], vec, sf.cal_cosine_similarity)\n",
    "recommendation_from_clf = df_jobs.iloc[jobs_top_n][['title', 'department', 'description_combined']]\n",
    "recommendation_from_clf_filtered = recommendation_from_clf[recommendation_from_clf['department'] == applicant['Category']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a classification model based on job description\n",
    "svm_clf = Pipeline([\n",
    "    ('tf', vec),\n",
    "    ('clf', svm_clfs['70']['estimator']),\n",
    "])\n",
    "\n",
    "svm_clf.fit(x_train_70, y_train_70)\n",
    "pred = svm_clf.predict(x_test_15)\n",
    "pred_resume = svm_clf.predict(df_resume['Resume_c'])\n",
    "accuracy = np.mean(pred_resume == df_resume['Category'])\n",
    "accuracy\n",
    "x_train_70.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get confusion matrix\n",
    "unique_labels = np.unique(df_jobs['department'])\n",
    "cf_report = hf.get_classification_report(unique_labels, y_test_15, pred)\n",
    "# select one user, recommend top-10 jobs\n",
    "applicant = df_resume.iloc[0]\n",
    "# model predict category of the resume\n",
    "pred_applicant = svm_clf.predict([applicant['Resume_c']])[0]\n",
    "jobs_top_n = hf.get_top_n_jobs_from_clf(df_jobs, pred_applicant, applicant['Resume_c'], vec, sf.cal_cosine_similarity)\n",
    "recommendation_from_svm_clf = df_jobs.iloc[jobs_top_n][['title', 'department', 'description_combined']]\n",
    "recommendation_from_svm_clf_filtered = recommendation_from_svm_clf[recommendation_from_svm_clf['department'] == applicant['Category']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a classification model based on job description\n",
    "knn_clf = Pipeline([\n",
    "    ('tf', vec),\n",
    "    ('clf', knn_clfs['80']['estimator']),\n",
    "])\n",
    "\n",
    "knn_clf.fit(x_train_80, y_train_80)\n",
    "pred = knn_clf.predict(x_test_10)\n",
    "pred_resume = knn_clf.predict(df_resume['Resume_c'])\n",
    "accuracy = np.mean(pred_resume == df_resume['Category'])\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get confusion matrix\n",
    "unique_labels = np.unique(df_jobs['department'])\n",
    "cf_report = hf.get_classification_report(unique_labels, y_test_10, pred)\n",
    "# select one user, recommend top-10 jobs\n",
    "applicant = df_resume.iloc[0]\n",
    "# model predict category of the resume\n",
    "pred_applicant = knn_clf.predict([applicant['Resume_c']])[0]\n",
    "pred_applicant == applicant['Category']\n",
    "jobs_top_n = hf.get_top_n_jobs_from_clf(df_jobs, pred_applicant, applicant['Resume_c'], vec, sf.cal_cosine_similarity)\n",
    "recommendation_from_knn_clf = df_jobs.iloc[jobs_top_n][['title', 'department', 'description_combined']]\n",
    "recommendation_from_knn_clf_filtered = recommendation_from_knn_clf[recommendation_from_knn_clf['department'] == applicant['Category']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Model(Kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = vec.transform(df_jobs['description_combined'])\n",
    "df_tfidf = pd.DataFrame(tfidf_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearnex import unpatch_sklearn\n",
    "unpatch_sklearn()\n",
    "from sklearn.cluster import KMeans\n",
    "from kneed import KneeLocator\n",
    "import plotly.graph_objects as go\n",
    "def elbow_method(data, number):\n",
    "    wcss = []\n",
    "    for i in range(1, number+1):\n",
    "        kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "        kmeans.fit(data)\n",
    "        wcss.append(kmeans.inertia_)\n",
    "    kn = KneeLocator(range(1, number+1), wcss, curve='convex', direction='decreasing')\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=list(range(1, number+1)),\n",
    "                            y=wcss))\n",
    "    fig.add_vline(x=kn.knee, line_width=3, line_dash=\"dash\", line_color=\"green\")\n",
    "\n",
    "    fig.update_layout(title='Elbow Method',\n",
    "                      xaxis_title='Number of clusters',\n",
    "                      yaxis_title='WCSS',\n",
    "                      title_x=0.5,\n",
    "                      height=500, \n",
    "                      width=800)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# render setting for vscode\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\"\n",
    "elbow_method(df_tfidf, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train clustering model\n",
    "applicant = df_resume.iloc[0]\n",
    "kmean_model = KMeans(n_clusters=len(np.unique(df_jobs['department'])), random_state=41)\n",
    "pred_kmeans_jobs = kmean_model.fit_predict(pd.DataFrame(vec.transform(df_jobs['description_combined']).toarray()))\n",
    "# prediction: number of cluster\n",
    "pred_kmeans_applicant = kmean_model.predict(vec.transform([applicant['Resume_c']]))[0] \n",
    "# add clustering label to data\n",
    "df_jobs['cluster'] = kmean_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_recommend_cluster = hf.get_top_n_jobs_from_cluster(df_jobs, pred_kmeans_applicant, applicant['Resume_c'], vec, sf.cal_cosine_similarity)\n",
    "recommendation_from_cluster = df_jobs.iloc[top_n_recommend_cluster][['title', 'department', 'description_combined']]\n",
    "recommendation_from_cluster_filtered = recommendation_from_cluster[recommendation_from_cluster['department'] == applicant['Category']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption: last 10% of the applicants got offers from their top-5 recommendation\n",
    "applicant_pool_with_offer = df_resume[:(int)(len(df_resume)*0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "applicant = df_resume.iloc[0]\n",
    "application_pool = applicant_pool_with_offer[applicant_pool_with_offer['Category'] == applicant['Category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = application_pool['Resume_c'].append(pd.Series(applicant['Resume_c']))\n",
    "matrix =vec.transform(temp)\n",
    "term_matrix = matrix.todense()\n",
    "cossim = sf.cal_cosine_similarity(term_matrix)\n",
    "index_similar_applicant = np.asarray(cossim[-1][np.where(cossim[-1] < 1)]).argsort()[::-1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_similar_applicant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_jobs = hf.get_top_n_jobs_from_cf(df_jobs, df_resume, index_similar_applicant, knn_clf, vec, sf.cal_cosine_similarity, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_from_cf = df_jobs.iloc[cf_jobs][['title', 'department', 'description_combined']]\n",
    "recommendation_from_cf_filtered = recommendation_from_cf[recommendation_from_cf['department'] == applicant['Category']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Recommendation Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "unpatch_sklearn()\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "def cal_cosine_similarity(term_matrix):\n",
    "    return cosine_similarity(term_matrix, term_matrix)\n",
    "\n",
    "def cal_jaccard_score(term_matrix):\n",
    "    return jaccard_score(term_matrix, term_matrix, average='samples')\n",
    "\n",
    "def cal_pearson_score(term_matrix):\n",
    "    return np.corrcoef(term_matrix, term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy for each department\n",
    "resumes = df_resume[:(int)(len(df_resume)*0.5)]['Resume_c']\n",
    "categories = df_resume[:(int)(len(df_resume)*0.5)]['Category']\n",
    "sim_method = cal_cosine_similarity\n",
    "unique_labels = df_jobs['department'].unique()\n",
    "accuracy_clf = dict()\n",
    "accuracy_cluster = dict()\n",
    "accuracy_cf = dict()\n",
    "for department in unique_labels:\n",
    "    accuracy_clf[department] = []\n",
    "    accuracy_cluster[department] = []\n",
    "    accuracy_cf[department] = []\n",
    "    resumes = df_resume[df_resume['Category'] == department]['Resume_c']\n",
    "    for i, resume in enumerate(resumes):\n",
    "#         # content-based with svm \n",
    "        pred_applicant_ = svm_clf.predict([resume])[0]\n",
    "        job_index = hf.get_top_n_jobs_from_clf(df_jobs, pred_applicant_, resume, vec, sim_method)\n",
    "        rec = df_jobs.iloc[job_index][['department']]\n",
    "        rec_filtered = rec[rec['department'] == department]\n",
    "        accuracy_clf[department].append(len(rec_filtered) / len(rec) if len(rec) != 0 else 0)\n",
    "        # content-based with kmeans\n",
    "        pred_applicant_ = kmean_model.predict(vec.transform([resume]))[0] \n",
    "        job_index = hf.get_top_n_jobs_from_cluster(df_jobs, pred_applicant_, resume, vec, sim_method)\n",
    "        rec = df_jobs.iloc[job_index][['department']]\n",
    "        rec_filtered = rec[rec['department'] == department]\n",
    "        accuracy_cluster[department].append(len(rec_filtered) / len(rec) if len(rec) != 0 else 0)\n",
    "        # cf\n",
    "        application_pool = applicant_pool_with_offer[applicant_pool_with_offer['Category'] == department]\n",
    "        temp = application_pool['Resume_c'].append(pd.Series(resume))\n",
    "        matrix =vec.transform(temp)\n",
    "        term_matrix = matrix.todense()\n",
    "        cossim = cal_cosine_similarity(term_matrix)\n",
    "        index_similar_applicant = np.asarray(cossim[-1][np.where(cossim[-1] < 1)]).argsort()[::-1][:10]\n",
    "        cf_jobs = hf.get_top_n_jobs_from_cf(df_jobs, df_resume, index_similar_applicant, svm_clf, vec, sim_method, 1)\n",
    "        rec = df_jobs.iloc[cf_jobs][['department']]\n",
    "        rec_filtered = rec[rec['department'] == categories.iloc[i]]\n",
    "        accuracy_cf[department].append(len(rec_filtered) / len(rec) if len(rec) != 0 else 0)\n",
    "\n",
    "for department in unique_labels:\n",
    "    accuracy_clf[department] = np.mean(accuracy_clf[department])\n",
    "    accuracy_cluster[department] = np.mean(accuracy_cluster[department])\n",
    "    accuracy_cf[department] = np.mean(accuracy_cf[department])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "list_y = [accuracy_clf[department] for department in accuracy_clf]\n",
    "fig.add_trace(go.Bar(x = unique_labels,\n",
    "                    name='SVM',\n",
    "                    y = list_y,\n",
    "                    text= list_y))\n",
    "list_y = [accuracy_cluster[department] for department in accuracy_cluster]\n",
    "fig.add_trace(go.Bar(x = unique_labels,\n",
    "                    name='KMeans',\n",
    "                    y = list_y,\n",
    "                    text= list_y))\n",
    "list_y = [accuracy_cf[department] for department in accuracy_cf]\n",
    "fig.add_trace(go.Bar(x = unique_labels,\n",
    "                    name='CF',\n",
    "                    y = list_y,\n",
    "                    text= list_y))\n",
    "                    \n",
    "fig.update_traces(texttemplate='%{text:.3f}', textposition='outside')\n",
    "fig.update_layout(\n",
    "    title_text='Recommendation Accuracy'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy for each department\n",
    "resumes = df_resume[:(int)(len(df_resume)*0.5)]['Resume_c']\n",
    "categories = df_resume[:(int)(len(df_resume)*0.5)]['Category']\n",
    "sim_method = sf.cal_pearson_score\n",
    "unique_labels = df_jobs['department'].unique()\n",
    "accuracy_clf = dict()\n",
    "accuracy_cluster = dict()\n",
    "accuracy_cf = dict()\n",
    "for department in unique_labels:\n",
    "    accuracy_clf[department] = []\n",
    "    accuracy_cluster[department] = []\n",
    "    accuracy_cf[department] = []\n",
    "    resumes = df_resume[df_resume['Category'] == department]['Resume_c']\n",
    "    print(resumes.shape)\n",
    "    for i, resume in enumerate(resumes):\n",
    "        # content-based with svm \n",
    "        pred_applicant_ = svm_clf.predict([resume])[0]\n",
    "        job_index = hf.get_top_n_jobs_from_clf(df_jobs, pred_applicant_, resume, vec, sim_method)\n",
    "        rec = df_jobs.iloc[job_index][['department']]\n",
    "        rec_filtered = rec[rec['department'] == department]\n",
    "        accuracy_clf[department].append(len(rec_filtered) / len(rec) if len(rec) != 0 else 0)\n",
    "        # content-based with kmeans\n",
    "        pred_applicant_ = kmean_model.predict(vec.transform([resume]))[0] \n",
    "        job_index = hf.get_top_n_jobs_from_cluster(df_jobs, pred_applicant_, resume, vec, sim_method)\n",
    "        rec = df_jobs.iloc[job_index][['department']]\n",
    "        rec_filtered = rec[rec['department'] == department]\n",
    "        accuracy_cluster[department].append(len(rec_filtered) / len(rec) if len(rec) != 0 else 0)\n",
    "        # cf\n",
    "        application_pool = applicant_pool_with_offer[applicant_pool_with_offer['Category'] == department]\n",
    "        temp = application_pool['Resume_c'].append(pd.Series(resume))\n",
    "        matrix =vec.transform(temp)\n",
    "        term_matrix = matrix.todense()\n",
    "        cossim = sf.cal_pearson_score(term_matrix)\n",
    "        index_similar_applicant = np.asarray(cossim[-1][np.where(cossim[-1] < 1)]).argsort()[::-1][:10]\n",
    "        cf_jobs = hf.get_top_n_jobs_from_cf(df_jobs, df_resume, index_similar_applicant, svm_clf, vec, sim_method, 1)\n",
    "        rec = df_jobs.iloc[cf_jobs][['department']]\n",
    "        rec_filtered = rec[rec['department'] == categories.iloc[i]]\n",
    "        accuracy_cf[department].append(len(rec_filtered) / len(rec) if len(rec) != 0 else 0)\n",
    "\n",
    "for department in unique_labels:\n",
    "    accuracy_clf[department] = np.mean(accuracy_clf[department])\n",
    "    accuracy_cluster[department] = np.mean(accuracy_cluster[department])\n",
    "    accuracy_cf[department] = np.mean(accuracy_cf[department])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "list_y = [accuracy_clf[department] for department in accuracy_clf]\n",
    "fig.add_trace(go.Bar(x = unique_labels,\n",
    "                    name='SVM',\n",
    "                    y = list_y,\n",
    "                    text= list_y))\n",
    "list_y = [accuracy_cluster[department] for department in accuracy_cluster]\n",
    "fig.add_trace(go.Bar(x = unique_labels,\n",
    "                    name='KMeans',\n",
    "                    y = list_y,\n",
    "                    text= list_y))\n",
    "list_y = [accuracy_cf[department] for department in accuracy_cf]\n",
    "fig.add_trace(go.Bar(x = unique_labels,\n",
    "                    name='CF',\n",
    "                    y = list_y,\n",
    "                    text= list_y))\n",
    "                    \n",
    "fig.update_traces(texttemplate='%{text:.3f}', textposition='outside')\n",
    "fig.update_layout(\n",
    "    title_text='Recommendation Accuracy'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "enc = OrdinalEncoder()\n",
    "\n",
    "y_true= [df_jobs['department'].append(pd.Series(df_resume.iloc[0]['Category']))]\n",
    "y_true = enc.fit_transform(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = df_jobs['description_combined'].append(pd.Series(df_resume.iloc[0]['Resume_c']))\n",
    "y_pred = [[svm_clf.predict([x])[0],0] for x in x_pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = enc.transform(y_pred[0])\n",
    "# # matrix = vec.transform(temp)\n",
    "# # term_matrix = matrix.todense()\n",
    "# sim_matrix = jaccard_score(y_true, y_pred, average='samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy for each department\n",
    "resumes = df_resume[:(int)(len(df_resume)*0.5)]['Resume_c']\n",
    "categories = df_resume[:(int)(len(df_resume)*0.5)]['Category']\n",
    "sim_method = sf.cal_jaccard_score\n",
    "unique_labels = df_jobs['department'].unique()\n",
    "accuracy_clf = dict()\n",
    "accuracy_cluster = dict()\n",
    "accuracy_cf = dict()\n",
    "for department in unique_labels:\n",
    "    accuracy_clf[department] = []\n",
    "    accuracy_cluster[department] = []\n",
    "    accuracy_cf[department] = []\n",
    "    resumes = df_resume[df_resume['Category'] == department]['Resume_c']\n",
    "    for i, resume in enumerate(resumes):\n",
    "        # content-based with knn \n",
    "        pred_applicant_ = svm_clf.predict([resume])[0]\n",
    "        job_index = hf.get_top_n_jobs_from_clf(df_jobs, pred_applicant_, resume, vec, sim_method)\n",
    "        rec = df_jobs.iloc[job_index][['department']]\n",
    "        rec_filtered = rec[rec['department'] == department]\n",
    "        accuracy_clf[department].append(len(rec_filtered) / len(rec) if len(rec) != 0 else 0)\n",
    "\n",
    "for department in unique_labels:\n",
    "    accuracy_clf[department] = np.mean(accuracy_clf[department])\n",
    "    accuracy_cluster[department] = np.mean(accuracy_cluster[department])\n",
    "    accuracy_cf[department] = np.mean(accuracy_cf[department])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_from_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_from_clf_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_from_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_from_cluster_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_from_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_from_cf_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_all_rec = [recommendation_from_cf, recommendation_from_clf, recommendation_from_cluster]\n",
    "all_recommendation = pd.concat(list_all_rec)\n",
    "all_recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_filtered_rec = [recommendation_from_cf_filtered, recommendation_from_clf_filtered, recommendation_from_cluster_filtered]\n",
    "final_recommendation = pd.concat(list_filtered_rec)\n",
    "final_recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_recommendation = all_recommendation[all_recommendation['department'] != applicant['Category']]\n",
    "false_recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_recommendation_matrix = vec.transform(false_recommendation['description_combined'])\n",
    "false_recommendation_matrix = false_recommendation_matrix.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import wordcloud\n",
    "\n",
    "index_false_rec = [5973, 2295, 962, 948]\n",
    "for it, target in enumerate(index_false_rec):\n",
    "    vec.get_feature_names_out()[target]\n",
    "    false_recommendation_word_list = []\n",
    "    for index in range(0, len(false_recommendation)):\n",
    "        a_list = []\n",
    "        word_indice = np.where(false_recommendation_matrix[index] != 0)[1]\n",
    "        for i in word_indice:\n",
    "            a_list.append(vec.get_feature_names_out()[i])\n",
    "        false_recommendation_word_list.append(a_list)\n",
    "        \n",
    "    text = ' '.join(false_recommendation_word_list[0])\n",
    "    wc = wordcloud.WordCloud(collocations=False, background_color='black', max_words=1000, \n",
    "                            max_font_size=50)\n",
    "    wc = wc.generate(text)\n",
    "    fig = plt.figure(num=it)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(wc, cmap=None)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = vec.transform([applicant['Resume_c']])\n",
    "b = b.todense()\n",
    "text = ' '.join(vec.get_feature_names_out()[np.where(b != 0)[1]])\n",
    "\n",
    "wc = wordcloud.WordCloud(collocations=False, background_color='black', max_words=100, \n",
    "                          max_font_size=50)\n",
    "wc = wc.generate(text)\n",
    "\n",
    "fig = plt.figure(num=1)\n",
    "plt.axis('off')\n",
    "plt.imshow(wc, cmap=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bias and variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.95, iterated_power='auto', svd_solver='auto', random_state=41)\n",
    "a = vec.transform(df_jobs['description_combined'])\n",
    "pca_a = pca.fit(a.todense())\n",
    "pca_a.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot([i for i in range(pca_a.n_components_)],\n",
    "        [np.sum(pca_a.explained_variance_ratio_[:i+1]) for i in range(pca_a.n_components_)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=pca_a.n_components_, random_state=41 )\n",
    "data = svd.fit_transform(vec.transform(df_jobs['description_combined']))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC(C=1, kernel='linear') # svm_clf_70\n",
    "svm_clf_reduced = svm_model.fit(svd.transform(vec.transform(x_train_70)), y_train_70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_department_reduced = svm_clf_reduced.predict(svd.transform(vec.transform(x_test_15)))\n",
    "np.mean(pred_department_reduced == y_test_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        svm_clf, x_train_70.values, df_jobs['encoded_department'][y_train_70.index].values, x_test_15.values, df_jobs['encoded_department'][y_test_15.index].values, \n",
    "        loss='mse',\n",
    "        random_seed=41)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        svm_clf_reduced, svd.transform(vec.transform(x_train_70.values)), df_jobs['encoded_department'][y_train_70.index].values,\n",
    "                        svd.transform(vec.transform(x_test_15.values)), df_jobs['encoded_department'][y_test_15.index].values, \n",
    "        loss='mse',\n",
    "        random_seed=41)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69eb92836b941e979072a76c7fcfffe5419cca933cedd02cfafbdfca1a93358c"
  },
  "kernelspec": {
   "display_name": "Python 3 (Intel® oneAPI 2023.0)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
